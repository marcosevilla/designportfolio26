# Case Study Assessment

An evaluation of all 6 case studies against industry best practices for senior/staff product design portfolios.

---

## Scoring Key

Each case study is evaluated on the 10 non-negotiables from the playbook research. Ratings: **Strong** (no action needed), **Adequate** (minor improvements), **Weak** (needs significant work).

---

## Portfolio-Level Assessment

### What's working across all 6

- **Specific customer names and quotes** — Every case study names real hotels, real stakeholders, and uses direct quotes. This is a major differentiator vs. most portfolios.
- **Business fluency** — CARR, enterprise deal values, adoption rates, KR achievement. You speak the language of business, not just design.
- **Cross-product connections** — Each case study references patterns from other projects (Compendium → F&B, KB → Compendium, Upsells → F&B modifiers). This is the strongest signal of systems thinking in the portfolio.
- **Honest reflection** — The "Would change" sections are genuinely specific and credible, not performative.
- **Named collaborators** — PMs, engineers, designers, stakeholders all named. Shows cross-functional fluency.

### What needs attention across all 6

1. **All case studies are too long for scanning.** The 60-second skim test fails — each is 200+ lines with dense paragraphs. A hiring manager or promotion reviewer will not read them end-to-end. Every case study needs ruthless editing or a clear visual hierarchy that lets someone get the story in 60 seconds and go deep selectively.

2. **No visuals anywhere yet.** Every visual is a TODO placeholder. This is the single biggest gap. Alicja Suska (1000+ reviews): annotated visuals are what people look at first and remember. The text-heavy format currently reads more like a project brief than a portfolio piece.

3. **Process sections lean toward chronological recitation.** HubSpot and Tanner Christensen both flag this as the #1 mistake. The "Iterations" subsections walk through month-by-month timelines rather than highlighting decision points and tensions. Consider restructuring around the 2-3 hardest moments or biggest pivots rather than chronological phases.

4. **Research → Decision connections could be tighter.** The research insights are numbered and each has a "→" connector, which is good. But in some cases the connection is restating the insight rather than showing the specific design change it caused. Make the arrow point to a specific UI element, not a general approach.

5. **Missing "failed directions."** None of the 6 case studies show a design direction that was explored and rejected. This is one of the strongest signals of senior thinking — showing what you tried, why it didn't work, and how it informed the final direction. Even one rejected approach per case study would strengthen the portfolio significantly.

6. **The opening hook is buried.** The Hero Section states the product description, but the actual hook — the business stakes, the "why now" — doesn't appear until The Problem section. Consider pulling one sentence of stakes into the hero.

---

## Case Study #1: F&B Mobile Ordering

**Overall: Strongest case study in the portfolio.** Highest ownership (100%), most detailed, best business context.

| Criterion | Rating | Notes |
|---|---|---|
| Lead with outcome | Adequate | Hero describes the product, not the impact. The $5.10 → $10 revenue goal would be a stronger opener. |
| Clarify your role | Strong | 100% ownership, clear. |
| Design judgment / trade-offs | Strong | No-POS decision, delivery-type model, modifier pre-selection debate with Becca. |
| Research → decisions | Strong | Each insight has a clear "→" to a design change. Hotel-specific examples (Chateau Avalon, HOMA). |
| Failed directions | Weak | No rejected approaches shown. The modal-to-full-page shift in Upsells is referenced but F&B doesn't show its own dead ends. |
| Annotated visuals | Weak | 10 TODO placeholders, zero actual visuals. |
| Quantify impact | Adequate | 50 pilot orders, verbal commitments, $2K/year savings quote. But no post-launch volume data yet (flagged with TODO). |
| Genuine reflection | Strong | Item remarks discoverability, staff notifications, AI menu parsing — all specific and actionable. |
| Scannable | Weak | ~230 lines, dense. The 5 key design decisions section is strong but the Process section is a wall of text. |
| Systems / staff-level thinking | Strong | System object model (5 objects), platform architecture for future ordering, prototype-to-GTM pipeline. |

### Suggestions

1. **Add a "hook" stat to the hero** — "Hotels lose 30% of potential F&B revenue to third-party delivery apps" or similar.
2. **Show one rejected direction** — Did you explore a POS-first approach before committing to no-POS? A full-app approach before web? Even briefly describing one explored-and-rejected path would strengthen the judgment signal.
3. **Trim the Process section** — The month-by-month chronology is thorough but reads like a timeline, not a story. Consider collapsing into 3 pivotal moments: (1) the no-POS decision, (2) the delivery-type insight, (3) the 6-scenario expansion.
4. **The new "5 system objects" decision (#3) is excellent** — but it currently reads more like documentation than a design decision. Add one sentence on why this IA was chosen over alternatives (e.g., "We could have built a simpler menu-only model, but that would have required rebuilding when modifiers and locations were added").

---

## Case Study #2: Digital Compendium

**Overall: Best platform-thinking case study.** 18-month arc, strongest revenue metrics ($1M+ CARR), demonstrates scale.

| Criterion | Rating | Notes |
|---|---|---|
| Lead with outcome | Adequate | Same issue — hero describes the product, not "$1M+ CARR, 175K MAU" which would hook instantly. |
| Clarify your role | Strong | 100% ownership, 11/11 files. |
| Design judgment / trade-offs | Strong | Builder vs. editor decision, custom sections extensibility, Lite constraints. |
| Research → decisions | Strong | COMO feedback, Best Western requirements, Eurostars benchmarking all connect to design choices. |
| Failed directions | Weak | No rejected approaches shown. Did you explore a free-form page editor before landing on structured builder? |
| Annotated visuals | Weak | 12 TODO placeholders, zero visuals. |
| Quantify impact | Strong | $1M CARR, 82% adoption, 175K MAU, 141% YoY growth. Best metrics across all 6 case studies. |
| Genuine reflection | Strong | COMO loss, analytics gap, Aman's feedback on user discovery. Honest and specific. |
| Scannable | Weak | ~245 lines. The 9-phase Process section is the longest across all case studies. |
| Systems / staff-level thinking | Strong | Platform architecture, cross-product pattern reuse, North Star brainstorm, freemium design as UX. |

### Suggestions

1. **The 9-phase chronology is too much.** Consider collapsing into 4 phases: Foundation (Jan–Aug '24), Guest Experience + Polish (Jul–Oct '24), Extensibility (Nov '24–Jun '25), Scale (Oct '25–present). The current breakdown has phases like "QR Templates + Manual Translation" that don't need their own section.
2. **The COMO loss is a strong story — elevate it.** The reflection mentions COMO explored Alliants. This is rare portfolio material — a case where the design wasn't enough. Consider adding one sentence to the Problem or Impact section about what this taught you about native app expectations vs. web-first approaches.
3. **Show the Figma prototype that "sold the product."** Wenjun's quote ("didn't we sell compendium over Figma prototypes?") is a powerful detail. This deserves more prominence — it demonstrates design as a business tool.

---

## Case Study #3: Upsells Forms

**Overall: Best "workflow design" case study.** Clear problem → solution arc, strong user quotes.

| Criterion | Rating | Notes |
|---|---|---|
| Lead with outcome | Adequate | Hero describes the form system. "Dream come true" — Hotel Jackson's quote — would be a more compelling hook. |
| Clarify your role | Strong | 63% ownership, clear scope. |
| Design judgment / trade-offs | Strong | Modal → full-page, "Questions not Fields" rename, scope-down to text-only MVP. |
| Research → decisions | Strong | Hotel Jackson, Guldsmeden, Amplitude data (95% mobile, 42% scroll). Clear cause-and-effect. |
| Failed directions | Weak | The modal → full-page is close to a "rejected direction" story but it's framed as an evolution, not a failed attempt. Were there intermediate approaches? |
| Annotated visuals | Weak | 10 TODO placeholders. |
| Quantify impact | Adequate | $3.8M CARR, 80% approval rate — but these are Upsells-wide, not Forms-specific. Forms adoption (TODO) would be more honest. |
| Genuine reflection | Strong | Dropdown MVP scope-down, guest-side discoverability, bug bash timing. |
| Scannable | Adequate | ~220 lines, slightly more manageable than F&B/Compendium. |
| Systems / staff-level thinking | Strong | Cross-product live preview conversation, Compendium pattern reuse, schemaform architecture. |

### Suggestions

1. **Be more precise about Forms-specific metrics.** The Quick Stats show Upsells-wide CARR ($3.8M) and approval rate (80%). These aren't Forms metrics. Either (a) flag clearly that these are Upsells-wide, or (b) replace with Forms-specific data (adoption %, reduction in messaging follow-ups).
2. **The "Questions not Fields" rename is a great story — lead with it.** This is the kind of user-informed naming decision that demonstrates craft. Consider making it the first Key Design Decision instead of #2.
3. **The new constraint-based UX decision (#4) is good** but overlaps with what's already in the Process section about dropdown limits. Consider merging the detail into decision #2 (form fields as "Guest Information") rather than standing alone.

---

## Case Study #4: Check-in Dashboard 2.0

**Overall: Most honest about shared ownership.** The 21% ownership framing is credible and mature.

| Criterion | Rating | Notes |
|---|---|---|
| Lead with outcome | Adequate | Long hero description. "~12% increase in reg card submission rate" is the hook. |
| Clarify your role | Strong | 21% ownership, specific contributions named (empty states, checklist, keyboard audit, IHG V2 screens). This is a model for shared-ownership case studies. |
| Design judgment / trade-offs | Adequate | The keyboard audit shows craft, but the design decisions are more about what was built than what was debated. |
| Research → decisions | Adequate | Competitive analysis (Duve) and conversion funnel data are strong. But the "→" connections are less sharp than in F&B or Upsells. |
| Failed directions | Weak | No rejected approaches. |
| Annotated visuals | Weak | 12 TODO placeholders. |
| Quantify impact | Strong | ~12% reg card increase, 100+ hotels, Wyndham 4,570+ sites. Specific and contextualized. |
| Genuine reflection | Strong | "Should have owned more of IHG V2," "keyboard audit was reactive," "didn't track metrics." Genuine and self-aware. |
| Scannable | Adequate | ~225 lines. The 4-phase structure is cleaner than Compendium. |
| Systems / staff-level thinking | Adequate | Keyboard UX as a foundational investment is a good systems argument, but the case study doesn't strongly demonstrate influence beyond the immediate project. |

### Suggestions

1. **The keyboard audit deserves a before/after.** This is one of the most tangible, measurable contributions — "X focus state issues found and fixed." Show the specific count and a before/after of one interaction.
2. **The conversion funnel data is buried.** "Registration card 60% → upsells 92% → ID 72% → credit card 80%" — this is compelling data that shows analytical thinking. Pull it higher, maybe into the Problem section as the evidence for why the redesign was needed.
3. **Strengthen the staff-level signal.** The keyboard audit established a baseline "across Canary's staff-facing products" — that's influence beyond the project. Emphasize this more. Did other teams reference it? Did it change how components were built?
4. **The enterprise pressure narrative is strong but could be sharper.** "Wyndham at the 99 yard line with another vendor" is a great detail. Frame the case study more explicitly around designing under enterprise deadline pressure — that's a senior-level story.

---

## Case Study #5: Above Property Portal

**Overall: Best IA/architecture case study.** Strong enterprise context, durable design decisions.

| Criterion | Rating | Notes |
|---|---|---|
| Lead with outcome | Adequate | Hero describes the product. "100% enterprise adoption" or "$18M Wyndham deal" would hook faster. |
| Clarify your role | Adequate | 40% ownership stated, but the boundary between Marco's work and Connor Swords' later work could be crisper. |
| Design judgment / trade-offs | Strong | Two-tier architecture, flexible portfolio model, progressive disclosure for permissions. Each is a genuine IA decision with rationale. |
| Research → decisions | Adequate | Insights connect to design, but the research methods are thinner than other case studies — no user testing with actual enterprise admins. The "Would change" section acknowledges this. |
| Failed directions | Weak | No rejected approaches. Did you explore a flat role model before landing on two-tier? A rigid hierarchy before flexible portfolios? |
| Annotated visuals | Weak | 8 TODO placeholders. |
| Quantify impact | Adequate | 100% adoption, 65→200+ users, $18M deal context. Strong qualitative but thin on operational metrics (time saved, CS tickets reduced). |
| Genuine reflection | Strong | Analytics scope gap, missing onboarding flow, no direct usability testing. Honest and actionable. |
| Scannable | Adequate | ~225 lines. Cleaner structure than F&B/Compendium. |
| Systems / staff-level thinking | Strong | The two-tier architecture became the standard across all Canary products. The naming decision influenced company-wide terminology. Both are strong staff-level signals. |

### Suggestions

1. **Add one rejected IA approach.** The two-tier architecture is strong, but showing that you explored alternatives (flat roles? three-tier? per-product roles?) would make the final decision more compelling.
2. **Sharpen the role boundary.** Lines 36 and 166 create slight tension: "Lead Designer (40% ownership)" but also "Connor Swords led the enterprise adoption project to completion." Add one sentence clarifying: "I designed the user management and portfolio management foundation (Dec 2023–Jun 2024). Connor led the enterprise adoption and expansion after I transitioned to other projects."
3. **The naming decision (#4) is interesting but minor.** Consider whether it belongs in Key Design Decisions or would be better as a note in the Design Process timeline. The first 3 decisions are structural IA choices; #4 is a terminology change.
4. **Quantify the CS/engineering time saved.** The Problem says "Engineering was regularly pulled in to script large-scale role changes." Can you estimate how many hours/month this consumed? Even "Engineering estimated X hours per enterprise role migration" would make the before/after more tangible.

---

## Case Study #6: Knowledge Base Redesign

**Overall: Best "foundational design" case study.** The 2-year validation arc is unique and compelling.

| Criterion | Rating | Notes |
|---|---|---|
| Lead with outcome | Weak | The hero describes the product, and the Quick Stats are process metrics (DSN-128, DSN-183). This is the weakest opening across all 6. The "Feb 2024 → Jan 2026 navigation prediction validated" is the real hook. |
| Clarify your role | Strong | Lead Designer on IA and UI, clear handoff story to Miguel. |
| Design judgment / trade-offs | Strong | Categorized structure, platform-level navigation, progressive disclosure with AI branching, friction principle. The new AI-aware branching decision is particularly strong. |
| Research → decisions | Strong | Pilot hotel visit, Caitlyn interview, Wyndham sensitivity to complexity, cross-product data sync question. |
| Failed directions | Weak | No rejected approaches shown. |
| Annotated visuals | Weak | 8 TODO placeholders. |
| Quantify impact | Weak | No business metrics. The case study relies entirely on design decisions and architectural influence. This is the weakest metrics section across all 6 — the TODO flag for KB V2 launch metrics is important to fill. |
| Genuine reflection | Strong | Not pushing for implementation, not prototyping completion metrics, insufficient handoff documentation. All specific and honest. |
| Scannable | Adequate | ~235 lines, but the "What happened after my design work" subsection is a unique and effective structural choice. |
| Systems / staff-level thinking | Strong | Platform-level thinking (where does this live?), cross-product data model (Compendium + KB), foundational IA that lasted 2 years. |

### Suggestions

1. **Restructure the Quick Stats urgently.** "DSN-128 + DSN-183" as a stat means nothing to anyone outside Canary. Replace with: the navigation prediction validation, the taxonomy durability (still in use 2 years later), the number of categories/subjects designed, or the KB V2 activation time reduction target.
2. **Lead with the prophecy.** The "Where does this live?" story — asked Feb 2024, validated Jan 2026 — is the single most compelling narrative in any of the 6 case studies. It should be in the hero or the first line of the Problem section, not buried in Key Design Decision #2.
3. **The three design approaches framework is strong.** The new addition (manual input easy → prefill → automate) is a great signal of strategic scoping. Consider making it more prominent — it shows you thought beyond the immediate ticket.
4. **This case study needs a "design that wasn't built" framing.** The honest story is: you did foundational design work that wasn't implemented for 18 months, then was validated when the team needed it. This is actually a powerful senior narrative — design that's so architecturally sound it survives without an advocate. Frame it positively rather than as a gap.

---

## Priority Actions (ranked by impact)

### Must-do (before showing the portfolio to anyone)

1. **Add visuals to at least 3-4 key TODOs per case study.** Export from Figma using the node links already in each Visual Gallery. Annotate each with a 1-sentence caption. Without visuals, this reads as a written report, not a design portfolio.

2. **Fix KB Quick Stats.** Replace Linear ticket numbers with meaningful metrics.

3. **Add one rejected/explored direction to each case study.** Even 2-3 sentences per case study showing an approach you considered and discarded.

### Should-do (significant quality improvement)

4. **Trim Process sections by ~40%.** Collapse chronological month-by-month into 3-4 pivotal moments per case study. Keep the detailed timeline available but make it scannable.

5. **Pull the hook into the hero.** For each case study, add one sentence of stakes/outcome to the hero section so the first thing a reader sees is "why this mattered."

6. **Add a TL;DR or summary card to each case study.** A 3-4 sentence block after the hero that gives the full story at a glance: problem, insight, solution, outcome.

### Nice-to-have (polish)

7. **Audit Quick Stats for Forms-specific and KB-specific metrics.** Replace product-wide metrics with feature-specific ones where possible.

8. **Consider reordering the portfolio.** Current implied order: F&B → Compendium → Upsells → Check-in → Above Property → KB. Strongest case for senior/staff promotion: lead with Compendium (platform thinking, best metrics, 18 months), then F&B (100% ownership, full-stack), then Above Property (enterprise IA), then KB (foundational thinking), then Upsells (craft), then Check-in (enterprise pressure, shared ownership).

9. **Add a portfolio intro page** with a compass statement: who you are, what kind of designer you are, what thread connects these 6 projects.

---

*Assessment completed February 2026. Based on research from HubSpot, Figma, GV, Tanner Christensen, Alicja Suska, and 15+ other sources. See CASE-STUDY-PLAYBOOK.md for full source list.*
